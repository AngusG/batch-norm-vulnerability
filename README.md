# batch-norm-vulnerability
Master source code repo for "Batch Normalization is a Cause of Adversarial Vulnerability"

- Section 1, Figure 1 and Appendix C: [Adversarial Spheres](https://github.com/AngusG/bn-adversarial-spheres)

- Section 3, Tables 1,2,3,4: SVHN / CIFAR-10 VGG experiments

- Section 3, Figures 2, 3: [MNIST MFT experiments](https://github.com/uoguelph-mlrg/bn-robust-mft). We reproduce the setup from [Yang et al., ICLR 2019](https://arxiv.org/abs/1902.08129) and evaluate the trainability and robustness of fully-connected networks with 10-60 layers for mini-batch sizes 5-250, with and without batch norm. 

- Section 3, Table 4: [CIFAR-10 and CIFAR-10-C experiments with unnormalized residual networks](https://github.com/AngusG/bn-advex-zhang-fixup). Repo contains two pre-trained checkpoints for ResNet110 (with and without batch norm).

- Section 4, Tables 6, 7, and Appendix B: Vulnerability and Input Dimension

Bibtex:  
```
@article{galloway2019batch,
  author = {Angus Galloway and Anna Golubeva and Thomas Tanay and Medhat Moussa and Graham Taylor},
  title = {Batch Normalization is a Cause of Adversarial Vulnerability},
  journal = {arXiv preprint arXiv:1905.02161},
  year = 2019
}
```
